{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9baa2424",
   "metadata": {},
   "source": [
    "# Initial Data Exploration and data processing\n",
    "\n",
    "### Pulling Dataset from [TrashNet](https://github.com/garythung/trashnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2913e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "import requests, zipfile, io\n",
    "dataset_url = \"https://github.com/garythung/trashnet/raw/master/data/dataset-resized.zip\"\n",
    "\n",
    "r = requests.get(dataset_url, stream=True)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7859b64",
   "metadata": {},
   "source": [
    "### Building npz package for FEDn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3926b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 types of data images.\n",
      "\n",
      "Processing cardboard images... Done.\n",
      "Processing glass images... Done.\n",
      "Processing metal images... Done.\n",
      "Processing paper images... Done.\n",
      "Processing plastic images... Done.\n",
      "Processing trash images... Done.\n",
      "\n",
      "Collected 2527 images of 6 types\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dir_path = \"dataset-resized\"\n",
    "\n",
    "# Pointing dataset to path\n",
    "if os.path.exists(\"__MACOSX\"):\n",
    "    shutil.rmtree(\"__MACOSX\")\n",
    "if os.path.exists(f\"{dir_path}/.DS_Store\"):\n",
    "    os.remove(f\"{dir_path}/.DS_Store\")\n",
    "\n",
    "dir_labels = os.listdir(dir_path)\n",
    "\n",
    "labeled_images = []\n",
    "for label in dir_labels:\n",
    "    labeled_images.append(glob.glob(os.path.join(dir_path, f'{label}/*')))\n",
    "print(f\"Found {len(dir_labels)} types of data images.\\n\")\n",
    "\n",
    "image_shape = (300, 300)\n",
    "\n",
    "img_data, labels = [], []\n",
    "for index, label in enumerate(dir_labels):\n",
    "    print(f\"Processing {label} images...\", end=\"\")\n",
    "    for img_path in labeled_images[index]:\n",
    "        image = Image.open(img_path).resize(image_shape)\n",
    "        img_data.append(np.asarray(image))\n",
    "        labels.append(index)\n",
    "    print(\" Done.\")\n",
    "print(f\"\\nCollected {len(img_data)} images of {len(dir_labels)} types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6415ff79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building data package\n",
      "data package saved as trashnet.npz\n"
     ]
    }
   ],
   "source": [
    "print(\"Building data package\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(img_data, labels, test_size=0.20, random_state=42)\n",
    "\n",
    "np.savez_compressed('trashNet', x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test)\n",
    "print(\"data package saved as trashnet.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fac20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning up images\n",
    "# shutil.rmtree(dir_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
